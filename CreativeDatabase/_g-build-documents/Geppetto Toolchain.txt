 
Geppetto Toolchain â€“ Å pecifikÃ¡cia (Archivon Orchestration Layer)
Ãšvod
Geppetto Toolchain rozÅ¡iruje platformu Geppetto o orchestraÄnÃº vrstvu, ktorÃ¡ spÃ¡ja najnovÅ¡ie postupy prÃ¡ce s GPT-4.1 a integruje externÃ© nÃ¡stroje pre zÃ­skavanie znalostÃ­ a vykonÃ¡vanie akciÃ­. CieÄ¾om je vytvoriÅ¥ produkÄnÃ½ toolchain umoÅ¾ÅˆujÃºci inteligentnÃ© vyuÅ¾itie Retrieval-Augmented Generation (RAG) aj GPT Actions v rÃ¡mci jednÃ©ho asistenta. V tomto dokumente integrujeme best practices z OpenAI Cookbook a definujeme architektÃºru, moduly a kÃ³d potrebnÃ½ pre robustnÃº orchestrÃ¡ciu.

HlavnÃ© vylepÅ¡enia a postupy:

GPT-4.1 Prompting Guide: V systÃ©me definujeme jasnÃº rolu asistenta (Geppetto ako â€œtool-using assistantâ€), pridÃ¡vame Å¡truktÃºrovanÃ© prÃ­klady pouÅ¾itia nÃ¡strojov, poskytujeme explicitnÃ© inÅ¡trukcie kedy a ako nÃ¡stroje volaÅ¥, a podporujeme chain-of-thought (plÃ¡novanie krok-za- krokom). Tieto techniky vyuÅ¾Ã­vajÃº vylepÅ¡enÃ© schopnosti GPT-4.1 efektÃ­vne plÃ¡novaÅ¥ a vyuÅ¾Ã­vaÅ¥ funkcie	.

OrchestrÃ¡cia nÃ¡strojov cez Responses API & RAG: VyuÅ¾Ã­vame novÃ½ OpenAI Responses API pre plynulÃ© volanie funkciÃ­ (tools) poÄas konverzÃ¡cie. Asistent tak mÃ´Å¾e automaticky pouÅ¾iÅ¥ vstavanÃ© Äi externÃ© nÃ¡stroje na zÃ¡klade pouÅ¾Ã­vateÄ¾skej poÅ¾iadavky. Integrujeme Pinecone vektorovÃº databÃ¡zu (indexovanie znalostnej bÃ¡zy a generovanie embeddingov) pre semanticÃ© vyhÄ¾adÃ¡vanie kontextu k dopytom. RelevantnÃ© informÃ¡cie zÃ­skanÃ© z vektorovÃ©ho vyhÄ¾adÃ¡vania sa injektujÃº do kontextu asistenta, ÄÃ­m minimalizujeme halucinÃ¡cie a zvÃ½Å¡ime presnosÅ¥ odpovedÃ­	.

GPT Actions (externÃ© akcie cez middleware): Rozhranie GPT Actions umoÅ¾Åˆuje prepojiÅ¥ asistenta s externÃ½mi sluÅ¾bami (napr. Salesforce CRM a Gong zÃ¡znamy hovorov) pomocou definovanÃ½ch akciÃ­. VytvorÃ­me schÃ©my akciÃ­ pre tieto sluÅ¾by (nÃ¡zov akcie, parametre, nÃ¡vratovÃ½ formÃ¡t) a zaregistrujeme ich do systÃ©mu tak, aby ich GPT vedel volaÅ¥. Volania sÃº sprostredkovanÃ© cez bezpeÄnÃ½ middleware (napr. serverless funkcie) â€“ asistent tak nemÃ¡ priamy prÃ­stup k API kÄ¾ÃºÄom, ale volÃ¡ definovanÃº akciu, ktorÃº backend spracuje	. KaÅ¾dÃ¡ akcia bude otestovanÃ¡
v izolÃ¡cii aj integraÄne, aby sme mali istotu, Å¾e GPT dokÃ¡Å¾e sprÃ¡vne vyvolaÅ¥ akciu a spracovaÅ¥ jej vÃ½sledok.

Tento dokument popisuje rozÅ¡Ã­renÃº architektÃºru Geppetta, obsahuje krokovÃ© inÅ¡trukcie spracovania dotazov, definuje novÃ© akcie a nÃ¡stroje, uvÃ¡dza ukÃ¡Å¾ky kÃ³dovÃ½ch modulov a vysvetÄ¾uje integrÃ¡ciu tÃ½chto komponentov do systÃ©mu. Dokument je pripravenÃ½ v produkÄnej kvalite, v sÃºlade s konvenciami Geppetta (Å¡truktÃºra sekciÃ­, znaÄky, timestampy a archivon kompatibilita). VÃ½sledkom je jeden sÃºhrnnÃ½ Å¡pecifikaÄnÃ½ sÃºbor (â€Geppetto Toolchain Specâ€œ), ktorÃ½ slÃºÅ¾i ako blueprint pre implementÃ¡ciu aj ÄalÅ¡ie rozÅ¡irovanie systÃ©mu.

RozÅ¡Ã­renÃ¡ architektÃºra orchestrÃ¡cie
NovÃ¡ vrstva orchestrÃ¡cie nÃ¡strojov v Geppettovi zavÃ¡dza komponenty, ktorÃ© umoÅ¾ÅˆujÃº dynamicky routovaÅ¥ poÅ¾iadavky pouÅ¾Ã­vateÄ¾a na internÃ© vyhÄ¾adÃ¡vanie informÃ¡ciÃ­ alebo externÃ© akcie. ArchitektÃºra zachovÃ¡va konverzaÄnÃ½ framework (LLM chat model) a pridÃ¡va k nemu tieto prvky:

System Prompt s definÃ­ciou nÃ¡strojov: SystÃ©movÃ© inÅ¡trukcie pre GPT-4.1 teraz obsahujÃº definÃ­cie dostupnÃ½ch nÃ¡strojov/funkciÃ­. KaÅ¾dÃ½ nÃ¡stroj mÃ¡ Å¡pecifikovanÃ½ nÃ¡zov, popis a Å¡truktÃºru volania (schema). Asistent vie, Å¾e mÃ´Å¾e tieto nÃ¡stroje vyuÅ¾iÅ¥ namiesto priamej odpovede, ak je to potrebnÃ©. Prompt tieÅ¾ zahÅ•Åˆa pripomienky k Ãºlohe asistenta, napr. aby najprv zvÃ¡Å¾il potrebu nÃ¡stroja pred odpoveÄou a aby premÃ½Å¡Ä¾al krokovo (tzv. chain-of-thought plÃ¡novanie)  . V
system message uvÃ¡dzame aj prÃ­kladovÃ© interakcie v sekcii	, ktorÃ© demonÅ¡trujÃº,
kedy pouÅ¾iÅ¥ napr. vyhÄ¾adÃ¡vanie v znalostnej bÃ¡ze alebo zavolaÅ¥ externÃº akciu â€“ tÃ½m model dostane jasnÃ½ vzor sprÃ¡vania	.

Registry nÃ¡strojov a akciÃ­: V backende je zavedenÃ½ register nÃ¡strojov â€“ centrÃ¡lna Å¡truktÃºra/ mapa, ktorÃ¡ eviduje vÅ¡etky dostupnÃ© nÃ¡stroje a GPT akcie. KaÅ¾dÃ¡ poloÅ¾ka obsahuje unikÃ¡tny identifikÃ¡tor alebo nÃ¡zov, referenciu na handler (funkciu/metÃ³du) a prÃ­padnÃ© metadata (napr. Äi ide o internÃ½ tool alebo externÃº akciu cez API). Register umoÅ¾Åˆuje jednoducho pridÃ¡vaÅ¥ alebo odoberaÅ¥ nÃ¡stroje bez zÃ¡sahu do logiky modelu â€“ staÄÃ­ aktualizovaÅ¥ zoznam a prÃ­sluÅ¡nÃ© popisy v systÃ©movom promte.

OrchestrÃ¡tor a routing poÅ¾iadaviek: HlavnÃ½ orchestrÃ¡tor (sÃºÄasÅ¥ Geppetto pipeline) sprostredkuje komunikÃ¡ciu medzi modelom a nÃ¡strojmi. Handler routing zabezpeÄuje, Å¾e ak

GPT vygeneruje volanie funkcie (napr. nasmeruje na sprÃ¡vny handler:
cez Responses API), systÃ©m ho zachytÃ­ a


Pre internÃ© vyhÄ¾adÃ¡vanie (RAG) je handler, ktorÃ½ zavolÃ¡ modul pre vektorovÃ© vyhÄ¾adÃ¡vanie (Pinecone).
Pre externÃ© GPT akcie (Salesforce, Gong) je handler, ktorÃ½ cez middleware vykonÃ¡ prÃ­sluÅ¡nÃº akciu.
OrchestrÃ¡tor taktieÅ¾ rozhodne o postupe: naprÃ­klad ak dotaz vyÅ¾aduje najprv vyhÄ¾adanie kontextu a potom externÃº akciu, proces mÃ´Å¾e zahÅ•ÅˆaÅ¥ viacero volanÃ­ nÃ¡strojov sekvenÄne. ArchitektÃºra podporuje multi-step interakcie, kde asistent mÃ´Å¾e postupne volaÅ¥ viac nÃ¡strojov (s plÃ¡novanÃ­m medzi krokmi), priÄom orchestrÃ¡tor kaÅ¾dÃ© volanie spracuje a odovzdÃ¡ modelu vÃ½sledky, aby mohol pokraÄovaÅ¥.

VektorovÃ¡ databÃ¡za & kontextovÃ½ modul: IntegrÃ¡cia Pinecone umoÅ¾Åˆuje ukladaÅ¥ internÃ© znalosti (dokumenty, poznÃ¡mky, historickÃ© dÃ¡ta) vo forme vektorovÃ½ch embeddingov a rÃ½chlo ich vyhÄ¾adÃ¡vaÅ¥ na zÃ¡klade podobnosti. NovÃ½ modul QueryContextEngine sa starÃ¡ o:

Indexovanie znalostÃ­: offline alebo na backgrounde vie prijÃ­maÅ¥ novÃ© dokumenty a ukladaÅ¥ ich do Pinecone indexu (pomocou embedding modelu GPT-4.1 alebo inÃ©ho).
Dopytovanie vektorov: na zÃ¡klade pouÅ¾Ã­vateÄ¾skej otÃ¡zky vygeneruje embedding dotazu a nÃ¡jde top relevantnÃ© pasÃ¡Å¾e/Ãºdaje.
NÃ¡vrat kontextu: zÃ­skanÃ© vÃ½sledky (napr. textovÃ© Ãºryvky) formÃ¡tuje do podoby vhodnej pre prompt (mÃ´Å¾e ich spojiÅ¥ do jednÃ©ho reÅ¥azca alebo ako bullet-pointy) a odovzdÃ¡ orchestrÃ¡toru.
Tento modul sa volÃ¡ buÄ automaticky pri kaÅ¾dom dotaze (pre-obohatenie kontextu), alebo
dynamicky len ak model o to poÅ¾iada volanÃ­m funkcie (napr.	). V praxi

vyuÅ¾ijeme kombinÃ¡ciu â€“ model je v systÃ©movÃ½ch inÅ¡trukciÃ¡ch navÃ¡dzanÃ½, aby pouÅ¾il vyhÄ¾adÃ¡vacÃ­ nÃ¡stroj, keÄ nemÃ¡ dostatok informÃ¡ciÃ­.

IntegrÃ¡cia externÃ½ch akciÃ­: Pre kaÅ¾dÃº externÃº sluÅ¾bu definujeme GPT Action, ktorÃ¡ predstavuje konkrÃ©tnu operÃ¡ciu (napr. vyhÄ¾adanie zÃ¡kaznÃ­ka v Salesforce podÄ¾a mena, alebo zÃ­skanie prepisu hovoru z Gong podÄ¾a ID zÃ¡znamu). Tieto akcie sÃº implementovanÃ© cez middleware â€“ naprÃ­klad serverless funkcia v AWS/Azure/GCP, ktorÃ¡ prijÃ­ma poÅ¾iadavku od GPT (cez nÃ¡Å¡ backend) a vykonÃ¡ volanie na externÃ© API. ArchitektÃºra predpokladÃ¡ nasledujÃºce kroky integrÃ¡cie:


Vytvorenie samotnej akcie v middleware (napr. endpoint Gong API).
Definovanie action schema pre GPT: Äo akcia robÃ­, akÃ© argumenty vyÅ¾aduje (napr.
volajÃºci


poÄ¾ami).
alebo
), a akÃ½ formÃ¡t vÃ½sledku vracia (napr. text prepisu alebo JSON s

RegistrÃ¡cia akcie v systÃ©me: zahrnutie popisu a schÃ©my do system promptu alebo ako sÃºÄasÅ¥
volania OpenAI API (napr. v poli	v ChatCompletion). TÃ½m model vie, Å¾e existuje

funkcia s danÃ½m menom a bude ju vedieÅ¥ zavolaÅ¥.
Handler v ActionDispatcher: V naÅ¡om kÃ³de modul

obsahuje logiku,

ktorÃ¡ prijme volanie akcie od modelu, spojÃ­ sa s prÃ­sluÅ¡nÃ½m middleware (napr. cez HTTP request s potrebnÃ½mi parametrami) a vrÃ¡ti vÃ½sledok.
Po obdrÅ¾anÃ­ vÃ½sledku orchestrÃ¡tor vloÅ¾Ã­ vÃ½sledok naspÃ¤Å¥ do kontextu konverzÃ¡cie (ako odpoveÄ funkcie), a model nÃ¡sledne dokonÄÃ­ odpoveÄ pre uÅ¾Ã­vateÄ¾a s vyuÅ¾itÃ­m zÃ­skanÃ½ch dÃ¡t.

SprÃ¡va akciÃ­ a bezpeÄnosti: OrchestrÃ¡cia zahÅ•Åˆa aj management vrstvy pre akcie, ktorÃ¡ dohliada na bezpeÄnÃ© a korektnÃ© vykonanie:

KaÅ¾dÃ© volanie akcie mÃ´Å¾e byÅ¥ logovanÃ© s timestampom, volanÃ½mi parametrami a stavom (Ãºspech/zlyhanie) pre audit a debug.
SystÃ©m mÃ´Å¾e maÅ¥ definovanÃ© obmedzenia, napr. limit poÄtu volanÃ­ externÃ½ch API v rÃ¡mci jednÃ©ho dotazu, alebo potrebu explicitnÃ©ho sÃºhlasu pouÅ¾Ã­vateÄ¾a pred "zÃ¡pisovÃ½mi" akciami (napr. ak by existovala akcia na zÃ¡pis do Salesforce, musÃ­ ju uÅ¾Ã­vateÄ¾ potvrdiÅ¥).
ChybovÃ© stavy (timeout API, nedostupnosÅ¥ sluÅ¾by) sÃº oÅ¡etrenÃ© â€“ ak akcia zlyhÃ¡, handler vrÃ¡ti
modelu informÃ¡ciu o zlyhanÃ­ a model buÄ skÃºsi alternatÃ­vu alebo sluÅ¡ne oznÃ¡mi uÅ¾Ã­vateÄ¾ovi, Å¾e danÃº akciu nemoÅ¾no vykonaÅ¥.
Å½iadna priama expozÃ­cia citlivÃ½ch Ãºdajov modelu: GPT vidÃ­ len vÃ½sledok volania (napr. "Company
X mÃ¡ rating A"), ale nedostane napr. priamo API kÄ¾ÃºÄ alebo nepotrebnÃ© surovÃ© dÃ¡ta. SystÃ©m prompt tieÅ¾ obsahuje upozornenie, aby model nevypisoval internÃ© formÃ¡ty Äi nepotvrdenÃ© informÃ¡cie.
Celkovo tÃ¡to architektÃºra prepojuje agentÃ­vne schopnosti GPT-4.1 (plÃ¡novanie, nÃ¡strojovÃ© volania) s robustnou backendovou infraÅ¡truktÃºrou. Geppetto tak dokÃ¡Å¾e pochopiÅ¥ otÃ¡zku, vyhÄ¾adaÅ¥ potrebnÃ½ kontext v internÃ½ch znalostiach a/alebo vykonaÅ¥ konkrÃ©tne Ãºlohy vo firemnÃ½ch aplikÃ¡ciÃ¡ch â€“ vÅ¡etko v rÃ¡mci jednÃ©ho konzistentnÃ©ho workflow. NasledujÃºce sekcie detailnejÅ¡ie opisujÃº kÄ¾ÃºÄovÃ© akcie, modulovÃ© komponenty a priebeh spracovania dotazu.

KÄ¾ÃºÄovÃ© nÃ¡stroje a akcie
V rozÅ¡Ã­renom Geppettovi pribÃºdajÃº novÃ© funkcie (tools) pre vyhÄ¾adÃ¡vanie informÃ¡ciÃ­ a akcie pre prÃ¡cu s externÃ½mi sluÅ¾bami. NiÅ¾Å¡ie uvÃ¡dzame hlavnÃ© nÃ¡stroje a akcie, vrÃ¡tane ich ÃºÄelu a spÃ´sobu pouÅ¾itia modelom:

(internÃ© vektorovÃ© vyhÄ¾adÃ¡vanie)
ÃšÄel: Poskytuje asistentovi relevantnÃ© informÃ¡cie z internej znalostnej bÃ¡zy pomocou vektorovÃ©ho vyhÄ¾adÃ¡vania. Model volÃ¡ tÃºto funkciu, keÄ potrebuje doplniÅ¥ znalosti, ktorÃ© nemÃ¡ v promptovom kontexte.
ImplementÃ¡cia: Volanie je obsluhovanÃ© modulom QueryContextEngine, ktorÃ½ vezme vstupnÃ½ dotaz,
vygeneruje embedding a dotÃ¡Å¾e sa Pinecone indexu. VÃ½stupom je krÃ¡tke zhrnutie nÃ¡jdenÃ½ch informÃ¡ciÃ­ (napr. top 3 relevantnÃ© pasÃ¡Å¾e).
Kedy sa volÃ¡: Iba ak je dotaz faktickÃ©ho charakteru mimo kontext alebo ak systÃ©movÃ½ prompt model navÃ¡dza, Å¾e by mal pre lepÅ¡iu odpoveÄ vyuÅ¾iÅ¥ znalostnÃº databÃ¡zu. Napr. na otÃ¡zku â€AkÃ© boli hlavnÃ© body poslednÃ©ho stretnutia?â€ model tuÅ¡Ã­, Å¾e odpoveÄ treba vyhÄ¾adaÅ¥ v poznÃ¡mkach, a preto zavolÃ¡
.
VÃ½stup: TextovÃ½ blok s kontextovÃ½mi Ãºdajmi, ktorÃ½ model nÃ¡sledne zahrnie do svojej odpovede. Funkcia nevracia odpoveÄ priamo uÅ¾Ã­vateÄ¾ovi, ale skÃ´r surovÃ© info pre model (model ho mÃ´Å¾e citovaÅ¥ alebo parafrÃ¡zovaÅ¥).
Obmedzenia: Funkcia nie je volanÃ¡ zbytoÄne â€“ model ju nepouÅ¾ije, ak uÅ¾ mÃ¡ odpoveÄ jasnÃº z kontextu
alebo ak otÃ¡zka nevyÅ¾aduje externÃ© znalosti. TieÅ¾ nevracia priveÄ¾a textu (limitujeme napr. na ~1000 tokenov), aby sa nevyÄerpal kontext okno zbytoÄne.

(externÃ¡ akcia â€“ Salesforce)
ÃšÄel: UmoÅ¾Åˆuje asistentovi zÃ­skaÅ¥ aktuÃ¡lne Ãºdaje zo Salesforce CRM, naprÃ­klad informÃ¡cie o zÃ¡kaznÃ­ckom ÃºÄte, otvorenÃ½ch prÃ­leÅ¾itostiach Äi poznÃ¡mkach. TypickÃ½ scenÃ¡r pouÅ¾itia je, keÄ uÅ¾Ã­vateÄ¾ poloÅ¾Ã­ otÃ¡zku tÃ½kajÃºcu sa zÃ¡kaznÃ­ka alebo dealu (napr. â€AkÃ½ je stav dealu s ABC Corp?â€œ).
ImplementÃ¡cia: TÃ¡to GPT akcia je prepojenÃ¡ s middleware, ktorÃ½ vykonÃ¡ SOQL dotaz alebo REST API
volanie do Salesforce. NaprÃ­klad akcia mÃ´Å¾e oÄakÃ¡vaÅ¥ parameter account_name a vrÃ¡tiÅ¥ zÃ¡kladnÃ© info o ÃºÄte a poslednÃ½ch aktivitÃ¡ch. Handler v ActionDispatcher prijme volanie (napr. search_salesforce({"account": "ABC Corp"}) ), zavolÃ¡ internÃº metÃ³du alebo HTTP request na integrÃ¡ciu so Salesforce a obdrÅ¾Ã­ JSON alebo textovÃ½ vÃ½sledok. Modelu sa ako vÃ½sledok akcie odovzdÃ¡ zhrnutie: napr. â€ÃšÄet ABC Corp: poslednÃ¡ aktivita 5 dnÃ­ dozadu, status prÃ­leÅ¾itosti = NegociÃ¡cia.â€œ.
Kedy sa volÃ¡: Iba keÄ uÅ¾Ã­vateÄ¾ova poÅ¾iadavka explicitne alebo implicitne vyÅ¾aduje data zo Salesforce. Model podÄ¾a promptu vie, Å¾e ak potrebuje CRM dÃ¡ta (napr. spomenutÃ© meno klienta, deal, alebo pipeline), mÃ¡ pouÅ¾iÅ¥ tÃºto akciu namiesto vymÃ½Å¡Ä¾ania. NevolÃ¡ sa bez dÃ´vodu â€“ pokiaÄ¾ otÃ¡zka nesÃºvisÃ­ so Salesforce dÃ¡tami, model ju nepouÅ¾ije.
VÃ½stup: StruÄnÃ¡ informÃ¡cia z CRM relevantnÃ¡ k dopytu. Model mÃ´Å¾e informÃ¡cie priamo zapracovaÅ¥ do odpovede pre uÅ¾Ã­vateÄ¾a (napr. â€œDeal s ABC Corp je v Å¡tÃ¡diu negociaâ€¦â€). CitlivÃ© polia (napr. internÃ© ID, Äi veÄ¾kosÅ¥ obchodu) sÃº buÄ vynechanÃ© alebo transformovanÃ© do uÅ¾Ã­vateÄ¾sky zrozumiteÄ¾nej formy podÄ¾a pravidiel definovanÃ½ch v prompte.

(externÃ¡ akcia â€“ Gong)
ÃšÄel: Poskytne asistentovi prÃ­stup k prepisom hovorov zo systÃ©mu Gong. UmoÅ¾Åˆuje naprÃ­klad vyhÄ¾adaÅ¥ a zÃ­skaÅ¥ prepis poslednÃ©ho hovoru s danÃ½m klientom. Toto je uÅ¾itoÄnÃ© v scenÃ¡ri, keÄ uÅ¾Ã­vateÄ¾ Å¾iada zhrnutie poslednÃ©ho callu alebo detaily z neho (napr. â€ÄŒo odznelo na poslednom hovore s ABC Corp?â€œ).

ImplementÃ¡cia: GPT akcia pre Gong je navrhnutÃ¡ tak, Å¾e oÄakÃ¡va identifikÃ¡tor hovoru (alebo inÃ½ parameter, podÄ¾a toho, Äo je dostupnÃ© â€“ napr. nÃ¡zov ÃºÄtu a dÃ¡tum, na zÃ¡klade Äoho middleware nÃ¡jde
sprÃ¡vny zÃ¡znam). Middleware (serverless funkcia) prijme poÅ¾iadavku od	, zavolÃ¡
Gong API endpoint pre zÃ­skanie transcriptu danÃ©ho hovoru a vÃ½sledok predspracuje (napr. vyÄistÃ­ formÃ¡t, mÃ´Å¾e skrÃ¡tiÅ¥ veÄ¾mi dlhÃ½ transcript). Handler nÃ¡sledne vrÃ¡ti buÄ celÃ© znenie (ak je krÃ¡tke), alebo relevantnÃ½ vÃ½Åˆatok Äi sÃºhrn.
Kedy sa volÃ¡: Len ak otÃ¡zka priamo smeruje na obsah hovorov. Model ju nebude volaÅ¥ pre vÅ¡eobecnÃ© otÃ¡zky. MÃ´Å¾e sa pouÅ¾iÅ¥ v kombinÃ¡cii so Salesforce akciou â€“ naprÃ­klad ak uÅ¾Ã­vateÄ¾ povie â€Priprav ma na
stretnutie s ABC Corpâ€œ, model mÃ´Å¾e najprv zavolaÅ¥	pre aktuÃ¡lny stav ÃºÄtu a
potom	pre poslednÃ½ hovor, a nÃ¡sledne odpovedaÅ¥ zhrnutÃ­m oboch zdrojov.
VÃ½stup: BuÄ surovÃ½ text hovoru (ak je to zvlÃ¡dnuteÄ¾nÃ© v kontexte), alebo zhrnutie kÄ¾ÃºÄovÃ½ch bodov z hovoru. V ideÃ¡lnom prÃ­pade middleware uÅ¾ vrÃ¡ti skrÃ¡tenÃ© body (napr. cez nejakÃ½ algoritmus alebo GPT- sumarizÃ¡ciu tam), aby model nemusel spracovÃ¡vaÅ¥ extrÃ©mne dlhÃ½ text. Model potom tieto informÃ¡cie spojÃ­ s ostatnÃ½mi a predstavÃ­ uÅ¾Ã­vateÄ¾ovi (napr. â€Na poslednom hovore (1. mÃ¡ja) sa preberalo: poÅ¾iadavka na zÄ¾avu, ÄalÅ¡ie demo budÃºci tÃ½Å¾deÅˆâ€¦â€œ).
Obmedzenia: Rovnako ako pri SF akcii, nevolÃ¡ sa bez relevantnosti. NavyÅ¡e, ak by transcript bol prÃ­liÅ¡
dlhÃ½, model by mohol rozhodnÃºÅ¥ spraviÅ¥ dodatoÄnÃ© skrÃ¡tenie (prompt ho k tomu nabÃ¡da â€“ napr. ak je vÃ½stup > N tokenov, navrhni len struÄnÃ© zhrnutie). InternÃ© citlivÃ© informÃ¡cie v prepise (napr. menÃ¡ konkurentov, ak by nemali byÅ¥ spomenutÃ©) mÃ´Å¾u byÅ¥ odstrÃ¡nenÃ© alebo zovÅ¡eobecnenÃ© podÄ¾a pravidiel.

(PoznÃ¡mka: Okrem vyÅ¡Å¡ie uvedenÃ½ch mÃ´Å¾u existovaÅ¥ aj ÄalÅ¡ie nÃ¡stroje/akcie, napr. jednoduchÃ½
pre vyhÄ¾adÃ¡vanie na internete, alebo akcie na vytvorenie zÃ¡znamu v inÃ½ch systÃ©moch. Tie vÅ¡ak nie sÃº jadrom tejto Å¡pecifikÃ¡cie a mÃ´Å¾u byÅ¥ doplnenÃ© neskÃ´r do registru nÃ¡strojov.)

KaÅ¾dÃ¡ z tÃ½chto funkciÃ­ a akciÃ­ je starostlivo zdokumentovanÃ¡ a otestovanÃ¡. Asistent mÃ¡ v systÃ©movÃ½ch inÅ¡trukciÃ¡ch explicitnÃ© pokyny kedy ktorÃº pouÅ¾iÅ¥. NaprÃ­klad: â€Ak otÃ¡zka obsahuje nÃ¡zov zÃ¡kaznÃ­ka alebo prÃ­leÅ¾itosti, pouÅ¾i search_salesforce . Ak obsahuje zmienku o hovore alebo stretnutÃ­, zvÃ¡Å¾ get_gong_transcript . Ak ide o vÅ¡eobecnÃº vedomosÅ¥ mimo aktuÃ¡lneho kontextu, pouÅ¾i search_vector_db .â€œ Tieto pokyny, spolu s prÃ­kladmi, pomÃ¡hajÃº modelu sprÃ¡vne rozhodovaÅ¥ o vyuÅ¾itÃ­ nÃ¡strojov. CieÄ¾om je, aby akcie prebehli iba vtedy, keÄ prinesÃº hodnotu pre odpoveÄ, a inak aby model odpovedal priamo z vlastnÃ½ch vedomostÃ­ Äi dodanÃ©ho kontextu.

ğŸªœ Postup spracovania dotazu (Workflow)
Aby systÃ©m fungoval spoÄ¾ahlivo, kaÅ¾dÃ¡ interakcia prechÃ¡dza pevne definovanÃ½m sledom krokov. NiÅ¾Å¡ie je workflow od prÃ­chodu uÅ¾Ã­vateÄ¾skej otÃ¡zky aÅ¾ po finÃ¡lnu odpoveÄ, s orchestrÃ¡ciou nÃ¡strojov a akciÃ­:

InicializÃ¡cia nÃ¡strojov: Pri spustenÃ­ (alebo deploymente) asistenta sa naÄÃ­tajÃº definÃ­cie
nÃ¡strojov	a	akciÃ­.	ToolRegistry	registruje	vÅ¡etky	funkcie	(	,
search_salesforce , get_gong_transcript , ...). OverÃ­ sa pripojenie k externÃ½m sluÅ¾bÃ¡m (napr. Pinecone client, dostupnosÅ¥ middleware endpointov). V systÃ©movom prompt-e sÃº vymenovanÃ© funkcie aj s popismi, aby model poznal ich ÃºÄel a signatÃºru.

PrÃ­chod otÃ¡zky od pouÅ¾Ã­vateÄ¾a: UÅ¾Ã­vateÄ¾ zadÃ¡ otÃ¡zku alebo poÅ¾iadavku. TÃ¡to sprÃ¡va je odovzdanÃ¡ orchestrÃ¡toru spolu s predpripravenÃ½m systÃ©movÃ½m promptom (obsahujÃºcim inÅ¡trukcie a moÅ¾no aj persistovanÃ½ chat kontext, ak ide o viac-kolovÃº konverzÃ¡ciu).

PredbeÅ¾nÃ© posÃºdenie dotazu: OrchestrÃ¡tor (alebo model samotnÃ½ na zÃ¡klade promptu) vyhodnotÃ­, Äi je potrebnÃ© vyhÄ¾adÃ¡vanie informÃ¡ciÃ­. PokiaÄ¾ systÃ©movÃ½ nÃ¡vrh hovorÃ­, aby najprv zvÃ¡Å¾il pouÅ¾itie RAG, model mÃ´Å¾e internÃ½m premÃ½Å¡Ä¾anÃ­m (chain-of-thought) rozhodnÃºÅ¥: â€MÃ¡m

dostatok info? Nie -> najprv pouÅ¾ijem	.â€œ. Toto premÃ½Å¡Ä¾anie nie je viditeÄ¾nÃ©
pouÅ¾Ã­vateÄ¾ovi, deje sa v rÃ¡mci modelu. Ak je dotaz triviÃ¡lny alebo ÄistÄ› konverzaÄnÃ½, model mÃ´Å¾e preskoÄiÅ¥ nÃ¡stroje a prejsÅ¥ priamo k tvorbe odpovede.

Volanie vyhÄ¾adÃ¡vacieho nÃ¡stroja (ak treba): Ak model indikoval potrebu kontextu, vygeneruje volanie funkcie search_vector_db namiesto priamej odpovede (OpenAI Responses API vrÃ¡ti function_call obsahujÃºci nÃ¡zov funkcie a argumenty, napr. dotaz). OrchestrÃ¡tor zachytÃ­ toto volanie a deleguje ho modulu QueryContextEngine. Ten vykonÃ¡ dotaz do Pinecone:

VypoÄÃ­ta embedding otÃ¡zky.
NÃ¡jde top	podobnÃ½ch vektorov v indexe.

ZÃ­ska prÃ­sluÅ¡nÃ© texty a skombinuje ich (napr. pridÃ¡ headingy pre kaÅ¾dÃ½ zdroj).
VrÃ¡ti zloÅ¾enÃ½ kontextovÃ½ text.

OrchestrÃ¡tor tento vÃ½sledok vloÅ¾Ã­ do konverzÃ¡cie ako odpoveÄ funkcie (



s nÃ¡zvom

a obsahom vÃ½sledku). TÃ½m pÃ¡dom model dostane do ÄalÅ¡ieho kroku konverzÃ¡cie
tieto novÃ© informÃ¡cie.

VyuÅ¾itie kontextu modelom: GPT-4.1 dostÃ¡va doplnenÃ½ kontext a pokraÄuje vo generovanÃ­ odpovede. Teraz uÅ¾ mÃ¡ k dispozÃ­cii aj pÃ´vodnÃº otÃ¡zku, aj relevantnÃ© Ãºdaje z kroku 4. V tejto fÃ¡ze model vytvorÃ­ nÃ¡vrh odpovede. ZÃ¡roveÅˆ vÅ¡ak zvaÅ¾uje, Äi nepotrebuje vykonaÅ¥ externÃº akciu (napr. overiÅ¥ aktuÃ¡lne dÃ¡ta). Ak Ã¡no, miesto dokonÄenia odpovede mÃ´Å¾e model opÃ¤Å¥ zvoliÅ¥ volanie funkcie â€“ tentoraz jednej z registrovanÃ½ch GPT akciÃ­.

Volanie externej akcie: Ak si to scenÃ¡r vyÅ¾aduje (napr. otÃ¡zka â€œAkÃ½ je aktuÃ¡lny stav ...?â€ a model vie, Å¾e to musÃ­ zistiÅ¥ v CRM), asistent vygeneruje  function_call pre prÃ­sluÅ¡nÃº akciu, napr. s	argumentom	"account":	"ABC	Corp"	alebo
s argumentom "call_id": "12345" . OrchestrÃ¡tor opÃ¤Å¥ zachytÃ­ toto volanie a odovzdÃ¡ ho ActionDispatcher modulu. Dispatcher podÄ¾a nÃ¡zvu nÃ¡jde zaregistrovanÃ½ handler:

Pre	napr. zavolÃ¡ metÃ³du, ktorÃ¡ poÅ¡le dotaz do Salesforce (cez API klienta
alebo HTTPS request na nÃ¡Å¡ middleware).
zavolÃ¡ prÃ­sluÅ¡nÃ½ endpoint middleware (napr. Azure Function) s

Handler poÄkÃ¡ na odpoveÄ od sluÅ¾by; ak to trvÃ¡ dlhÅ¡ie, mÃ´Å¾e async streamovaÅ¥ Äi indikovaÅ¥ stav (v jednoduchom prÃ­pade blokujÃºco poÄkÃ¡ niekoÄ¾ko sekÃºnd).
Po ÃºspeÅ¡nom zÃ­skanÃ­ dÃ¡t handler spracuje raw vÃ½sledok (napr. JSON z API) do textovej formy alebo krÃ¡tkeho zhrnutia.

NÃ¡vrat vÃ½sledku akcie modelu: OrchestrÃ¡tor vloÅ¾Ã­ vÃ½sledok externej akcie naspÃ¤Å¥ do kontextu konverzÃ¡cie, podobne ako pri vyhÄ¾adÃ¡vanÃ­, vo forme odpovede funkcie. Role je opÃ¤Å¥
(nÃ¡zov napr.	) a content obsahuje textovÃ½ vÃ½stup (napr. â€ABC Corp â€“
poslednÃ¡ aktivita pred 5 dÅˆami, next step: zaslaÅ¥ nÃ¡vrh zmluvy.â€œ). Model teraz dostÃ¡va v konverzÃ¡cii tieto dÃ¡ta.

Generovanie finÃ¡lnej odpovede: Model mÃ¡ vÅ¡etky potrebnÃ© informÃ¡cie (Äi uÅ¾ z Pinecone, Salesforce, Gong, alebo ich kombinÃ¡cie) a dokonÄÃ­ odpoveÄ pre uÅ¾Ã­vateÄ¾a. V tomto kroku (ktorÃ½
mÃ´Å¾e byÅ¥ pokraÄovanÃ­m toho istÃ©ho	turnu alebo novÃ½m turnom po funkÄnom
volanÃ­) model skombinuje poznatky a sformuluje sÃºvislÃº odpoveÄ v prirodzenom jazyku. Napr.

â€Stretnutie s ABC Corp prebehlo dobre â€“ podÄ¾a CRM je deal vo fÃ¡ze negociÃ¡cie (poslednÃ¡ aktivita pred 5 dÅˆami) a z prepisu poslednÃ©ho hovoru vyplÃ½va, Å¾e klient Å¾iada upraviÅ¥ cenovÃº ponuku. OdporÃºÄam pripraviÅ¥ aktualizovanÃ½ nÃ¡vrh a ozvaÅ¥ sa do konca tÃ½Å¾dÅˆa.â€œ. Model neuvÃ¡dza, Å¾e robil nejakÃ© vyhÄ¾adÃ¡vanie Äi akcie â€“ odpoveÄ prezentuje plynule, akoby mal informÃ¡cie okamÅ¾ite (pokiaÄ¾ to nie je neÅ¾iadÃºce; v niektorÃ½ch prÃ­padoch mÃ´Å¾eme promptom model viesÅ¥ k tomu, aby uviedol zdroje informÃ¡ciÃ­ Äi ÄalÅ¡ie kroky, ale spravidla to nie je potrebnÃ©).

Odovzdanie odpovede uÅ¾Ã­vateÄ¾ovi: FinÃ¡lna odpoveÄ je vrÃ¡tenÃ¡ klientskej aplikÃ¡cii (UI) a prezentovanÃ¡ uÅ¾Ã­vateÄ¾ovi. CelÃ½ proces prebehol interaktÃ­vne v rÃ¡mci sekÃºnd. UÅ¾Ã­vateÄ¾ vidÃ­ len zÃ¡vereÄnÃº odpoveÄ a prÃ­padnÃ© citÃ¡cie Äi referencie (ak by sme implementovali, Å¾e model uvÃ¡dza zdroje z vector search, mÃ´Å¾e pripojiÅ¥ referenciu alebo linku â€“ to by sa muselo definovaÅ¥ v prompte; niekedy staÄÃ­ uviesÅ¥ â€(zdroj: internÃ¡ databÃ¡za)â€œ ak to situÃ¡cia vyÅ¾aduje).

UkonÄenie cyklu a logovanie: OrchestrÃ¡tor uzavrie jedno kolo interakcie. Do logov/monitoringu sa zaznamenÃ¡, akÃ© nÃ¡stroje boli pouÅ¾itÃ© a s akÃ½m vÃ½sledkom. NaprÃ­klad log mÃ´Å¾e obsahovaÅ¥:

Query: "OtÃ¡zka uÅ¾Ã­vateÄ¾a", Tools used: [
,
], Outcome:

success, Latency: XY ms. Tieto dÃ¡ta poslÃºÅ¾ia na ladenie (napr. ak model zbytoÄne volÃ¡ urÄitÃ© akcie, vieme upraviÅ¥ prompt) a na monitoring vÃ½konu systÃ©mu. NÃ¡sledne je systÃ©m pripravenÃ½ prijaÅ¥ ÄalÅ¡Ã­ dotaz (v kontexte chat session alebo novÃº session).

PoznÃ¡mka: Ak ide o viac-kolovÃº konverzÃ¡ciu, kontext (histÃ³ria) sa posiela modelu vÅ¾dy znova spolu s novÃ½m dotazom, takÅ¾e model mÃ¡ vedomosÅ¥ o predchÃ¡dzajÃºcich odpovediach. Napriek tomu vÅ¡ak neuchovÃ¡vame skrytÃ© stavovÃ© informÃ¡cie mimo tento mechanizmus â€“ vÅ¡etko podstatnÃ© musÃ­ byÅ¥ v promptoch. Vector store (Pinecone) obsahuje len statickÃ© znalosti, nie obsah predchÃ¡dzajÃºcich user queries (pokiaÄ¾ by sme nechceli implementovaÅ¥ dlhodobÃº pamÃ¤Å¥, Äo zatiaÄ¾ nie je zÃ¡mer). KaÅ¾dÃ½ cyklus tak prebieha deterministicky podÄ¾a vyÅ¡Å¡ie uvedenÃ½ch krokov.

Tento workflow zaisÅ¥uje, Å¾e systÃ©m nevynechÃ¡ Å¾iadny dÃ´leÅ¾itÃ½ krok: ak je potrebnÃ© nieÄo vyhÄ¾adaÅ¥ alebo zavolaÅ¥, spravÃ­ to v sprÃ¡vnom poradÃ­. Preskakovanie krokov nie je povolenÃ© â€“ naprÃ­klad model nemÃ¡ priamo odhadovaÅ¥ odpoveÄ z Salesforce bez volania akcie, ani orchestrÃ¡tor nesmie zabudnÃºÅ¥ poskytnÃºÅ¥ zÃ­skanÃ© dÃ¡ta modelu pred finÃ¡lnym zodpovedanÃ­m. V nasledujÃºcej Äasti uvÃ¡dzame implementaÄnÃ© detaily kÄ¾ÃºÄovÃ½ch modulov, ktorÃ© tento workflow podporujÃº.

â›” DÃ´leÅ¾itÃ© obmedzenia a pravidlÃ¡
Pri nÃ¡vrhu a implementÃ¡cii Geppetto Toolchain je nevyhnutnÃ© dodrÅ¾iavaÅ¥ urÄitÃ© obmedzenia a pravidlÃ¡, aby systÃ©m fungoval sprÃ¡vne a bezpeÄne:

Å½iadne vymÃ½Å¡Ä¾anie mimo nÃ¡stroje: Model nesmie halucinovaÅ¥ fakty, ktorÃ© by mal zÃ­skaÅ¥ nÃ¡strojmi. Prompt explicitne uvÃ¡dza, aby asistent pouÅ¾il dostupnÃ© nÃ¡stroje namiesto fabulÃ¡cie. Ak naprÃ­klad pouÅ¾Ã­vateÄ¾ Å¾iada aktuÃ¡lne ÄÃ­sla alebo Ãºdaje z CRM, model mÃ¡ vedieÅ¥, Å¾e musÃ­ pouÅ¾iÅ¥ prÃ­sluÅ¡nÃº akciu. VyhÃ½bame sa situÃ¡cii, Å¾e by model odpovedal nepresne len preto, Å¾e â€œnevedelâ€ o existencii nÃ¡stroja.

NepouÅ¾Ã­vaÅ¥ neregistrovanÃ© akcie: Asistent je inÅ¡truovanÃ½ drÅ¾aÅ¥ sa len ponÃºknutÃ½ch funkciÃ­. Nemal by skÃºÅ¡aÅ¥ volaÅ¥ neexistujÃºce funkcie alebo formovaÅ¥ vlastnÃ© API volania. OrchestrÃ¡tor to technicky ani nedovolÃ­ â€“ pokus o volanie neznÃ¡mej funkcie sa loguje ako chyba a model dostane odpoveÄ, Å¾e funkcia neexistuje (prÃ­padne v budÃºcnosti by sme mohli model promptom upozorniÅ¥). To chrÃ¡ni pred nepredvÃ­danÃ½mi vÃ½stupmi.

ReÅ¡pektovanie limitov a chÃ½b: Model aj orchestrÃ¡tor musia reÅ¡pektovaÅ¥, ak nÃ¡stroj nevrÃ¡ti vÃ½sledok alebo ak nastane chyba. Model podÄ¾a promptu vie, Å¾e ak akcia vrÃ¡ti napr. "NenÃ¡jdenÃ©" alebo orchestrÃ¡tor signalizuje zlyhanie, mÃ¡ sluÅ¡ne informovaÅ¥ uÅ¾Ã­vateÄ¾a, Å¾e danÃ© dÃ¡ta nie sÃº dostupnÃ©, a nepokraÄovaÅ¥ v nepravdivom kontexte. ZÃ¡roveÅˆ, ak vector search niÄ relevantnÃ© nenaÅ¡lo, model by nemal na silu tie Ãºdaje potrebovaÅ¥ â€“ buÄ odpovie "nemÃ¡m informÃ¡ciu" alebo skÃºsi inÃº stratÃ©giu (napr. spÃ½taÅ¥ sa uÅ¾Ã­vateÄ¾a na spresnenie).

Å½iadne odhaÄ¾ovanie internÃ½ch procesov: UÅ¾Ã­vateÄ¾ nemÃ¡ vidieÅ¥ "do zÃ¡kulisia". Model nesmie vypÃ­saÅ¥ systÃ©movÃ© inÅ¡trukcie, nÃ¡zvy funkciÃ­, surovÃ© dÃ¡ta z vector store Äi API volanÃ­, pokiaÄ¾ to vyslovene nepatrÃ­ do odpovede. NaprÃ­klad nebude hovoriÅ¥ "VyhÄ¾adal som tÃºto informÃ¡ciu v databÃ¡ze..." (pokiaÄ¾ by to nebol poÅ¾adovanÃ½ Å¡tÃ½l). V prompt-e je zahrnutÃ©, Å¾e chain-of-thought a technickÃ© detaily majÃº ostaÅ¥ skrytÃ©.

TaktieÅ¾, ak v prepisu hovoru sÃº citlivÃ© alebo nepotvrdenÃ© vÃ½roky, asistent ich neodprezentuje ako fakty bez kontextu.
OsobnÃ© Ãºdaje a bezpeÄnosÅ¥: Pri prÃ¡ci s reÃ¡lnymi dÃ¡tami dodrÅ¾iavame zÃ¡sady ochrany Ãºdajov. Model mÃ¡ zakÃ¡zanÃ© poskytovaÅ¥ dÃ¡ta, na ktorÃ© uÅ¾Ã­vateÄ¾ nemÃ¡ prÃ¡vo alebo ktorÃ© nesÃºvisia s jeho otÃ¡zkou.

Bez pretrvÃ¡vajÃºcej pamÃ¤te asistenta: Asistent (GPT model) sÃ¡m osebe neuchovÃ¡va stav medzi session. KaÅ¾dÃ½ dotaz spracuje na zÃ¡klade predloÅ¾enÃ©ho kontextu a nÃ¡strojov. NemÃ¡ dlhodobÃº pamÃ¤Å¥ v tom zmysle, Å¾e by si pamÃ¤tal predchÃ¡dzajÃºce dotazy mimo kontextu. (Ak by sme chceli dlhodobÃº pamÃ¤Å¥, musÃ­me ju implementovaÅ¥ cez ukladanÃ­ konverzÃ¡ciÃ­ a prÃ­padne ich indexovanie do Pinecone, ale to je inÃ¡ Ãºloha.) Builder GPT nemÃ¡ dopad na toto sprÃ¡vanie poÄas behu â€“ ide o odliÅ¡nÃº vrstvu.

TransakÄnÃ© akcie len s povolenÃ­m: (Pre budÃºcnosÅ¥) Ak by do systÃ©mu pribudli akcie, ktorÃ© menia Ãºdaje (napr. vytvorenie zÃ¡znamu v Salesforce, odoslanie emailu, naplÃ¡novanie meetingu), budÃº vyÅ¾adovaÅ¥ dodatoÄnÃ© pravidlÃ¡: napr. uÅ¾Ã­vateÄ¾ to musÃ­ priamo prikÃ¡zaÅ¥ alebo potvrdiÅ¥ nÃ¡vrh. V aktuÃ¡lnej verzii mÃ¡me len read-only akcie, takÅ¾e model niÄ nemenÃ­, len ÄÃ­ta. Ale architektÃºra rÃ¡ta s tÃ½m, Å¾e pribudnÃº aj akcie so side-effectami, kde zavedie mechanizmus potvrdenia.

DodrÅ¾iavanie tÃ½chto pravidiel je kritickÃ©. UÅ¾ pri testovanÃ­ budeme kontrolovaÅ¥, Äi model neporuÅ¡uje tieto zÃ¡sady (napr. skÃºsime ho "zmiasÅ¥" otÃ¡zkou mimo kontext a sledujeme, Äi nepovie nezmysel namiesto
pouÅ¾itia	). V produkcii sa budÃº relevantnÃ© poruÅ¡enia logovaÅ¥ a mÃ´Å¾eme pridaÅ¥
sentinelovÃ© kontroly (napr. jednoduchÃ½ post-process na vÃ½stup, ktorÃ½ zachytÃ­, Äi model nezaÄal vypisovaÅ¥ nieÄo ako "Function call: ..."). TÃ½mto predÃ­deme neÅ¾iadÃºcemu sprÃ¡vaniu a zachovÃ¡me dÃ´veryhodnosÅ¥ asistenta.

ğŸ“¦ ImplementÃ¡cia modulov a skriptov
NasledujÃº definÃ­cie hlavnÃ½ch modulov zavedenÃ½ch v rÃ¡mci Geppetto Toolchain. KaÅ¾dÃ½ modul obsahuje hlaviÄku s nÃ¡zvom sÃºboru, popisom ÃºÄelu, vstupov a vÃ½stupov, a nÃ¡sledne nÃ¡Ärt implementÃ¡cie. KÃ³d je pÃ­sanÃ½ tak, aby dodrÅ¾iaval Å¡tÃ½l a konvencie Geppetta (dokumentaÄnÃ© reÅ¥azce, syntax pre logovanie,
atÄ.). Tieto moduly budÃº sÃºÄasÅ¥ou kÃ³dovej bÃ¡zy Geppetto (napr. v adresÃ¡ri	).


# pinecone_connector.py """
Modul pre integrÃ¡ciu s Pinecone vektorovou databÃ¡zou.
ÃšÄel: Poskytuje funkcie na indexovanie dokumentov (uloÅ¾enie embeddingov) a na vyhÄ¾adÃ¡vanie relevantnÃ½ch dokumentov podÄ¾a dotazu.
Vstupy:
Pri inicializÃ¡cii: konfiguraÄnÃ© Ãºdaje (API kÄ¾ÃºÄ, nÃ¡zov indexu).
Pre indexovanie: zoznam dokumentov (textov) a ich ID alebo metadÃ¡ta.
Pre vyhÄ¾adÃ¡vanie: dopyt (textovÃ½ reÅ¥azec) alebo priamo embedding vektory, plus parameter top_k urÄujÃºci poÄet vÃ½sledkov.
VÃ½stupy:
Pri indexovanÃ­: ÃºspeÅ¡nosÅ¥ operÃ¡cie (napr. True/False alebo poÄet indexovanÃ½ch zÃ¡znamov).
Pri vyhÄ¾adÃ¡vanÃ­: zoznam vÃ½sledkov s metadÃ¡tami (napr. [(score, doc_id, text), ...]) alebo skombinovanÃ½ text relevantnÃ½ch Ãºryvkov.
"""

import pinecone
from openai.embeddings_utils import get_embedding # hypotetickÃ¡ utilita na zÃ­skanie embedding

class PineconeConnector:
def   init  (self, api_key: str, environment: str, index_name: str): pinecone.init(api_key=api_key, environment=environment) self.index = pinecone.Index(index_name)
self.index_name = index_name

def index_documents(self, docs: dict[str, str]): """
Indexuje dokumenty vo Pinecone.
docs: slovnÃ­k mapujÃºci ID dokumentu na text dokumentu.
Pre kaÅ¾dÃ½ dokument vygeneruje embedding a uloÅ¾Ã­ ho do indexu spolu s ID. NÃ¡vrat: poÄet ÃºspeÅ¡ne indexovanÃ½ch dokumentov.
"""
vectors = []
for doc_id, text in docs.items():
# vygenerovaÅ¥ embedding (napr. pomocou OpenAI modelu alebo inÃ©ho) embedding = get_embedding(text)
vectors.append((doc_id, embedding, {"text": text})) if vectors:
self.index.upsert(vectors) return len(vectors)

def query(self, query_text: str, top_k: int = 5) -> list[tuple[float, str, str]]: """
VyhÄ¾adÃ¡ najpodobnejÅ¡ie dokumenty k zadanÃ©mu dotazu. query_text: textovÃ½ dotaz pouÅ¾Ã­vateÄ¾a.
top_k: poÄet najbliÅ¾Å¡Ã­ch vÃ½sledkov, ktorÃ© sa majÃº vrÃ¡tiÅ¥.
NÃ¡vrat: zoznam top_k vÃ½sledkov vo forme tuple(score, doc_id, text).

"""
# zÃ­skaÅ¥ embedding dotazu
query_vec = get_embedding(query_text)
results = self.index.query(vector=query_vec, top_k=top_k, include_metadata=True) hits = []
for match in results.matches: score = match.score doc_id = match.id
text = match.metadata.get("text", "") hits.append((score, doc_id, text))
return hits


PoznÃ¡mky  k	pinecone_connector.py :  Tento  modul  enkapsuluje  prÃ¡cu  s  Pinecone.  Funkcia
index_documents predpokladÃ¡, Å¾e dokumenty sÃº dodanÃ© v podobe slovnÃ­ka (	),
vygeneruje ich embedding (pouÅ¾Ã­vame utilitu get_embedding â€“ v realite by to bola vÃ½zva na OpenAI
API alebo lokÃ¡lny model) a vloÅ¾Ã­ ich do indexu pomocou upsert . Pri vyhÄ¾adÃ¡vanÃ­	taktieÅ¾ volÃ¡
embedding na dotaz a potom Pinecone query . VÃ½sledky obsahujÃº skÃ³re podobnosti, ID a uloÅ¾enÃ½ text. V produkcii by sme moÅ¾no neukladali celÃ½ text do metadÃ¡t (kvÃ´li veÄ¾kosti), ale tu pre jednoduchosÅ¥ predpokladÃ¡me, Å¾e text je v metadata (alternatÃ­vne by tam mohol byÅ¥ odkaz na uloÅ¾isko dokumentu). Tento modul sa pouÅ¾Ã­va v QueryContextEngine na zÃ­skanie relevantnÃ½ch Ãºryvkov.



# query_context_engine.py

"""
Modul pre zÃ­skavanie kontextu na zÃ¡klade pouÅ¾Ã­vateÄ¾skej otÃ¡zky. ÃšÄel: Abstrahuje logiku Retrieval-Augmented Generation.
VyuÅ¾Ã­va PineconeConnector na nÃ¡jdenie relevantnÃ½ch info a spracuje ich pre prompt.
Vstupy:
PineconeConnector (inicializovanÃ½ na prÃ­sluÅ¡nÃ½ index znalostnej bÃ¡zy).
UÅ¾Ã­vateÄ¾skÃ½ dotaz (string).
Parametre vyhÄ¾adÃ¡vania (napr. top_k vÃ½sledkov, voliteÄ¾nÃ½ filter).
VÃ½stupy:
KontextovÃ½ blok textu pre model: buÄ jednotlivÃ© nÃ¡jdenÃ© Ãºryvky s odrÃ¡Å¾kami
alebo zlepenÃ½ text s oddelenÃ­m, ktorÃ½ sa vloÅ¾Ã­ do promptu alebo odovzdÃ¡ modelu ako vÃ½sledo
"""
from typing import Optional class QueryContextEngine:
def   init  (self, pinecone_connector: PineconeConnector, max_chars: int = 1000): self.db = pinecone_connector
self.max_chars = max_chars # maximÃ¡lna dÄºÅ¾ka vrÃ¡tenÃ©ho kontextu

def get_context(self, user_query: str, top_k: int = 5) -> str: """
VyhÄ¾adÃ¡ relevantnÃ© dokumenty k dotazu a vygeneruje kontextovÃ½ text.
Najprv dotazuje Pinecone cez PineconeConnector.
Potom spracuje vÃ½sledky: zoradÃ­ podÄ¾a score a spojÃ­ do jednÃ©ho textu.

SkrÃ¡ti vÃ½slednÃ½ text, ak presahuje max_chars.
NÃ¡vrat: textovÃ½ kontext pripravenÃ½ na vloÅ¾enie do promptu. """
hits = self.db.query(user_query, top_k=top_k) if not hits:
return "" # niÄ nenaÅ¡lo

# ZoradiÅ¥ podÄ¾a score zostupne (ak Pinecone nevrÃ¡ti uÅ¾ zoradenÃ©) hits.sort(key=lambda x: x[0], reverse=True)
context_parts = []
for score, doc_id, text in hits: snippet = text.strip()
if not snippet: continue
# PridaÅ¥ odrÃ¡Å¾ku alebo inÃ½ oddelovaÄ medzi Ãºryvkami context_parts.append(f"- {snippet}")
context_text = "\n".join(context_parts) # skrÃ¡tenie na max_chars (ak treba)
if len(context_text) > self.max_chars:
context_text = context_text[:self.max_chars] + "â€¦" return context_text

def get_context_as_list(self, user_query: str, top_k: int = 5) -> list[str]: """
AlternatÃ­vna metÃ³da: vrÃ¡ti zoznam Ãºryvkov (bez formÃ¡tovania do jednÃ©ho stringu), ak by sme chceli odovzdaÅ¥ vÃ½sledky inÃ½m spÃ´sobom.
"""
hits = self.db.query(user_query, top_k=top_k) snippets = [hit[2].strip() for hit in hits if hit[2]] return snippets

PoznÃ¡mky k  query_context_engine.py : Tento modul stavia na	a poskytuje
metÃ³du  get_context , ktorÃº vyuÅ¾ije orchestrÃ¡tor pri spracovanÃ­ dotazu (napr. v kroku 4 workflow
vyÅ¡Å¡ie). get_context zavolÃ¡ Pinecone, obdrÅ¾Ã­ zoznam	(score, id, text). NÃ¡sledne z nich zostavÃ­
textovÃ½ kontext: - V tomto prÃ­klade kaÅ¾dÃ½ vÃ½sledok formÃ¡tujeme ako odrÃ¡Å¾ku (	). PrÃ­padne
by sa mohlo formÃ¡tovaÅ¥ inak, napr. "Document X: snippet". - OÅ¡etrÃ­me prÃ¡zdny text a oreÅ¾eme celÃ½ blok, ak by bol prÃ­liÅ¡ dlhÃ½ (aby sme nepreÅ¥aÅ¾ili prompt). - Poskytuje aj metÃ³du
pre prÃ­pad, Å¾e by orchestrÃ¡tor chcel pracovaÅ¥ s listom a formÃ¡tovaÅ¥ inde (tÃº moÅ¾no nevyuÅ¾ijeme, ale ukazuje flexibilitu).

Tento engine skrÃ½va detaily Pinecone od zvyÅ¡ku kÃ³du â€“ inde v pipeline staÄÃ­ zavolaÅ¥
a dostaÅ¥ reÅ¥azec. Ak niÄ relevantnÃ© nie je nÃ¡jdenÃ©, vrÃ¡ti prÃ¡zdny string (orchestrÃ¡tor potom vie, Å¾e nemÃ¡ Äo pridaÅ¥ modelu).



ÃšÄel: PrijÃ­ma volania funkciÃ­ od modelu (GPT Actions), nÃ¡jde zodpovedajÃºcu akciu v registri a vykonÃ¡ ju prostrednÃ­ctvom middleware alebo API klienta.
Vstupy:
Register akciÃ­: slovnÃ­k nÃ¡zov -> handler funkcia/objekt.
Volanie akcie od modelu: typicky obsahuje nÃ¡zov akcie a argumenty.
VÃ½stupy:
VÃ½sledok volania: text alebo Å¡truktÃºra, ktorÃ¡ sa odovzdÃ¡ modelu (ako funkÄnÃ½ vÃ½stup). """

import requests import json
from typing import Callable


class ActionDispatcher: def   init  (self):
# Registry akciÃ­: nÃ¡zov akcie -> funkcia, ktorÃ¡ ju vykonÃ¡.
# Funkcia musÃ­ akceptovaÅ¥ kwargs (parametre akcie) a vrÃ¡tiÅ¥ vÃ½stup (str self.action_handlers: dict[str, Callable[..., str]] = {}




alebo dict).


def register_action(self, action_name: str, handler_func: Callable[..., str]): """
Zaregistruje novÃº akciu do dispatchera.
action_name: meno akcie tak, ako ho pouÅ¾Ã­va model (napr. 'search_salesforce'). handler_func: funkcia, ktorÃ¡ implementuje volanie (napr. self._call_salesforce). """
self.action_handlers[action_name] = handler_func

def dispatch(self, action_name: str, params: dict) -> str: """
VykonÃ¡ akciu podÄ¾a nÃ¡zvu s danÃ½mi parametrami.
Najprv overÃ­, Äi akcia existuje v registri.
Potom zavolÃ¡ prÃ­sluÅ¡nÃ½ handler a vrÃ¡ti jeho vÃ½sledok (ako string).
Ak akcia nie je nÃ¡jdenÃ¡ alebo nastane chyba, vyhodÃ­ vÃ½nimku alebo vrÃ¡ti chybovÃ© hlÃ¡s """
if action_name not in self.action_handlers:
raise ValueError(f"Action '{action_name}' is not registered") handler = self.action_handlers[action_name]
try:
result = handler(**params)
# Ak je vÃ½stup slovnÃ­k/objekt, konvertujeme na string (JSON) pre model, # alebo ak mÃ¡ byÅ¥ text, tak priamo string.
if isinstance(result, (dict, list)):
return json.dumps(result, ensure_ascii=False) else:
return str(result) except Exception as e:
# Log chyby a preposlaÅ¥ jednoduchÃº sprÃ¡vu Äalej print(f"[ActionDispatcher] Chyba pri volanÃ­ akcie {action_name}: {e}") # JednoduchÃ¡ signalizÃ¡cia zlyhania (mÃ´Å¾e byÅ¥ rozvinutÃ© podÄ¾a potreby) return "ERROR: Action execution failed"

# PrÃ­klady internÃ½ch handlerov pre konkrÃ©tne akcie:
def _call_salesforce(self, account: str) -> str: """
InternÃ½ handler: vyhÄ¾adÃ¡ informÃ¡cie o ÃºÄte v Salesforce cez middleware. account: nÃ¡zov ÃºÄtu
NÃ¡vrat: textovÃ© zhrnutie info alebo chybovÃ¡ sprÃ¡va. """
try:
# Predpokladajme, Å¾e existuje konfiguraÄnÃ¡ URL na naÅ¡e middleware API url = "https://our-middleware.example.com/salesforce_search"
payload = {"account": account}
resp = requests.post(url, json=payload, timeout=5) resp.raise_for_status()
data = resp.json()
# PredpokladanÃ½ formÃ¡t data: {"account_name": ..., "status": ..., "last_activity": # TransformÃ¡cia na text:
account_name = data.get("account_name", account) status = data.get("status", "neznÃ¡my status") last_act = data.get("last_activity", "nezistenÃ©")
return f"ÃšÄet {account_name}: status={status}, poslednÃ¡ aktivita={last_act}." except Exception as e:
# Chyba pri volanÃ­ externÃ©ho servisu print(f"SF action error: {e}")
return "Nepodarilo sa zÃ­skaÅ¥ Ãºdaje zo Salesforce."

def _call_gong(self, call_id: str) -> str: """
InternÃ½ handler: zÃ­ska prepis hovoru z Gong cez middleware.
call_id: identifikÃ¡tor hovoru (alebo inÃ½ identifikÃ¡tor potrebnÃ½ k zÃ­skaniu zÃ¡znamu). NÃ¡vrat: textovÃ½ vÃ½stup (napr. zhrnutie hovoru alebo jeho ÄasÅ¥).
"""
try:
url = "https://our-middleware.example.com/gong_get_transcript" payload = {"call_id": call_id}
resp = requests.get(url, params=payload, timeout=5) resp.raise_for_status()
data = resp.json()
transcript = data.get("transcript", "") if not transcript:
return "Pre danÃ© ID nebol nÃ¡jdenÃ½ Å¾iadny zÃ¡znam hovoru." # MoÅ¾nÃ© skrÃ¡tenie transcriptu ak je dlhÃ½:
summary = transcript if len(summary) > 500:
summary = summary[:500] + "â€¦"
return f"Transcript hovoru {call_id}: {summary}" except Exception as e:
print(f"Gong action error: {e}")
return "Nepodarilo sa naÄÃ­taÅ¥ prepis hovoru."

PoznÃ¡mky k	: Tento modul je zodpovednÃ½ za vykonanie externÃ½ch akciÃ­ na
zÃ¡klade volania od modelu. KÄ¾ÃºÄovÃ© komponenty:

	slovnÃ­k, kde kÄ¾ÃºÄ je nÃ¡zov akcie (string, ako ho model poznÃ¡) a hodnota je funkcia v Pythone, ktorÃ¡ tÃº akciu vykonÃ¡.
	metÃ³da umoÅ¾Åˆuje zaregistrovaÅ¥ novÃ© akcie. V praxi by sme ju volali pri inicializÃ¡cii orchestrÃ¡tora, napr.:


TÃ½mto spÃ¡rujeme nÃ¡zvy s implementÃ¡ciami.
je hlavnÃ¡ metÃ³da pouÅ¾Ã­vanÃ¡ orchestrÃ¡torom: odovzdÃ¡ nÃ¡zov akcie a parametre
(napr. z GPT function call	), a zÃ­ska naspÃ¤Å¥ vÃ½sledok ako string. RobÃ­ aj zÃ¡kladnÃ©
oÅ¡etrenie: ak akcia nie je registrovanÃ¡, vyhodÃ­ chybu; ak nastane vÃ½nimka poÄas behu handlera,

zachytÃ­ ju a vrÃ¡ti text
promptu pre model, tu zjednoduÅ¡ene).
InternÃ© metÃ³dy konkrÃ©tne sluÅ¾by:


a
(prÃ­padne by to mohlo vloÅ¾iÅ¥ do ilustrujÃº, ako mÃ´Å¾u vyzeraÅ¥ volania na

	: posiela POST na nÃ¡Å¡ middleware endpoint pre Salesforce (predpokladÃ¡me existenciu). Dostane JSON s Ãºdajmi a zloÅ¾Ã­ z neho jednovetovÃº informÃ¡ciu.
	: posiela GET na endpoint pre Gong transcript, dostane JSON (moÅ¾no obsahuje celÃ½ transcript). Pre dlhÃ½ text robÃ­ skrÃ¡tenie.
Tieto funkcie vracajÃº stringy pripravenÃ© pre model. (V jednoduchÅ¡om prÃ­pade by sme rovno
mohli modelu vrÃ¡tiÅ¥ JSON a nechaÅ¥ ho to sformÃ¡tovaÅ¥, ale to je komplikovanejÅ¡ie pre model, radÅ¡ej poskytneme uÅ¾ text.)
V skutoÄnosti by tieto volania mali obsahovaÅ¥ aj autentifikÃ¡ciu (napr. API kÄ¾ÃºÄe v headeroch), ale tie detaily tu nie sÃº vypisovanÃ©. PredpokladÃ¡ sa, Å¾e middleware nepotrebuje extra auth od nÃ¡s,
alebo Å¾e	pouÅ¾ije nejakÃ© uloÅ¾enÃ© tokeny.
Timeouty a error handlovanie: nastavili sme timeout 5s, a chyby logujeme	-om (v reÃ¡le
by to Å¡lo do loggera Geppetto). Pri chybe vraciame zrozumiteÄ¾nÃ© sprÃ¡vy v slovenÄine, ktorÃ© vÅ¡ak
model dostane v	odpovedi â€“ model je inÅ¡truovanÃ½, aby pri takomto texte buÄ skÃºsil
inÃº stratÃ©giu, alebo uÅ¾Ã­vateÄ¾ovi povedal, Å¾e nastala chyba. (Napr. ak dostane "Nepodarilo sa zÃ­skaÅ¥ Ãºdaje zo Salesforce.", tak finÃ¡lna odpoveÄ mÃ´Å¾e byÅ¥ "OspravedlÅˆujem sa, momentÃ¡lne sa nepodarilo zÃ­skaÅ¥ Ãºdaje zo Salesforce." alebo nieÄo podobnÃ©.)
Tieto modulovÃ© implementÃ¡cie spolupracujÃº nasledovne: QueryContextEngine pouÅ¾Ã­va PineconeConnector pre RAG, a ActionDispatcher vyuÅ¾Ã­va registrÃ¡ciu vlastnÃ½ch handlerov pre GPT Actions. OrchestrÃ¡tor (ktorÃ½ nie je explicitne vyÄlenenÃ½ ako samostatnÃ½ modul tu) by bol zodpovednÃ½ za:
- InicializÃ¡ciu PineconeConnector (s potrebnÃ½mi kÄ¾ÃºÄmi a indexom). - InicializÃ¡ciu QueryContextEngine s tÃ½m connectorom. - InicializÃ¡ciu ActionDispatcher a registrÃ¡ciu dostupnÃ½ch akciÃ­. - Potom v runtime: zachytÃ¡vanie function_call od modelu a rozhodovanie Äi pouÅ¾iÅ¥   QueryContextEngine   (pre   search_vector_db )   alebo   ActionDispatcher   (pre
, get_gong_transcript atÄ.), a nÃ¡slednÃ© odosielanie vÃ½sledkov modelu.

CelÃ½  tento  kÃ³d  je  pÃ­sanÃ½  modulÃ¡rne,  Äo  uÄ¾ahÄuje  testovanie:  mÃ´Å¾eme  jednotlivo  testovaÅ¥
pinecone_connector (mocknÃºÅ¥ Pinecone a skÃºsiÅ¥ index/query), testovaÅ¥
(s	mock	PineconeConnector	ktorÃ½	vrÃ¡ti	pÃ¡r	hitov,	skontrolovaÅ¥	formÃ¡t	vÃ½stupu),	aj

(pomocou dummy funkciÃ­ namiesto reÃ¡lnych requestov overiÅ¥, Å¾e dispatch funguje). IntegrÃ¡cia sa testuje v end-to-end scenÃ¡roch popÃ­sanÃ½ch niÅ¾Å¡ie.

Testovanie a finÃ¡lny stav systÃ©mu
Po implementÃ¡cii uvedenÃ½ch komponentov nasleduje dÃ´kladnÃ© testovanie na Ãºrovni jednotiek aj celÃ©ho systÃ©mu, aby sme overili, Å¾e Geppetto Toolchain funguje podÄ¾a oÄakÃ¡vanÃ­:

JednotkovÃ© testy modulov: Pre kaÅ¾dÃ½ modul sme pripravili testy:
	: testujeme index_documents (Äi vrÃ¡ti sprÃ¡vny poÄet a volÃ¡ Pinecone API korektne â€“ to mÃ´Å¾eme simulovaÅ¥) a query (Äi sprÃ¡vne spracuje vÃ½sledky z Pinecone â€“ tu pouÅ¾ijeme mock objekt napodobÅˆujÃºci self.index.query nÃ¡vrat).

: pripravÃ­me umelÃ½ zoznam hitov a overÃ­me, Å¾e
reÅ¥azec s oÄakÃ¡vanÃ½m formÃ¡tom (odrÃ¡Å¾ky, orezanie). TieÅ¾ test na prÃ¡zdny vÃ½sledok.
vrÃ¡ti


action_dispatcher : vyskÃºÅ¡ame register + dispatch s jednoduchou lambda funkciou (napr.
handler=lambda  x:  "OK" ),  Äi  to  preteÄie  sprÃ¡vne.  Pre	a
_call_gong mÃ´Å¾eme vyuÅ¾iÅ¥ nÃ¡stroj	na simulÃ¡ciu odpovede z API (napr.
vrÃ¡time znÃ¡my JSON a skontrolujeme, Å¾e vÃ½stupnÃ¡ string obsahuje oÄakÃ¡vanÃ© info). Otestujeme aj vetvu, kde akcia nie je zaregistrovanÃ¡, vyhodÃ­ sa vÃ½nimka.

IntegraÄnÃ© testy (suchÃ½ beh): Simulujeme celÃ½ proces s kontrolovanÃ½m prostredÃ­m:

VytvorÃ­me instancie modulov (s Pinecone v test reÅ¾ime alebo s malÃ½m lokÃ¡lnym indexom, prÃ­p. stub, aby test bol deterministickÃ½).
Nasimulujeme scenÃ¡r 1: dotaz, ktorÃ½ vyÅ¾aduje iba RAG. Napr. otÃ¡zka: "What is XYZ?" kde
vieme, Å¾e odpoveÄ je v knowledge base. OverÃ­me, Å¾e:
Model by mal zavolaÅ¥	(to vieme podÄ¾a promptu, ale v teste mÃ´Å¾eme
priamo zavolaÅ¥ QueryContextEngine, keÄÅ¾e model sa nesimuluje kompletne).
VÃ½sledok z QueryContextEngine (fake data) by iÅ¡iel modelu a model by vygeneroval odpoveÄ (tu staÄÃ­ skontrolovaÅ¥, Å¾e by dostal sprÃ¡vny text).
FinÃ¡lna odpoveÄ obsahuje info z toho textu.
ScenÃ¡r 2: dotaz, ktorÃ½ potrebuje Salesforce akciu. Napr. "AkÃ½ je stav dealu s ACME Corp?":
Po initializÃ¡cii test promptu by model mal zvoliÅ¥
(v teste priamo zavolÃ¡me dispatcher.dispatch).
My pripravÃ­me mock	aby vrÃ¡til napr. "ÃšÄet ACME Corp:
status=Negotiation, last_activity=2025-05-01.".
OÄakÃ¡vame, Å¾e finÃ¡lna odpoveÄ (tu by sme museli trochu model sprÃ¡vanie predpokladaÅ¥ alebo to testovaÅ¥ s pomocou GPT cez API so zadanou function) obsahuje tieto Ãºdaje.
ScenÃ¡r 3: komplexnÃ½ dotaz (viac akciÃ­): "Priprav ma na stretnutie s ABC Corp." â€“ oÄakÃ¡vame postup: Salesforce -> Gong -> odpoveÄ. OverÃ­me, Å¾e ak volÃ¡me sekvenÄne dispatcher pre
a potom	, a dÃ¡me modelu oba vÃ½sledky do
promptu, tak vÃ½slednÃ¡ odpoveÄ kombinuje informÃ¡cie (toto je skÃ´r manuÃ¡lny test s GPT v loop-e alebo analyzovanÃ­m promptu, ale dÃ¡ sa automatizovaÅ¥ v rÃ¡mci sandbox prostredia OpenAI API s nastavenÃ½m funkciami).

ManuÃ¡lne testy a ladenie chain-of-thought: SpustÃ­me Geppetto Toolchain v testovacom prostredÃ­ (napr. konzola alebo internÃ½ UI) a poloÅ¾Ã­me niekoÄ¾ko otÃ¡zok. Sledujeme logy orchestrÃ¡tora, aby sme videli, kedy model volÃ¡ funkcie. Napr. dotaz: "ÄŒo si hovoril s XYZ na poslednom hovore a akÃ© sÃº ÄalÅ¡ie kroky v obchode?"

OÄakÃ¡vanÃ© sprÃ¡vanie: model najprv zavolÃ¡	(dostane status obchodu),
potom	(dostane body z hovoru), a potom odpovie. V logu uvidÃ­me dve
volania a finÃ¡lnu odpoveÄ. OverÃ­me, Å¾e odpoveÄ je konzistentnÃ¡ a Å¾e model nepovedal niÄ nevhodnÃ©.
TaktieÅ¾ vyskÃºÅ¡ame otÃ¡zku, kde nÃ¡stroje nemÃ¡ pouÅ¾iÅ¥ (napr. "Ahoj, ako sa mÃ¡Å¡?"). OÄakÃ¡vame, Å¾e model priamo odpovie bez volania funkcie. Toto nÃ¡m overÃ­, Å¾e nespÃºÅ¡Å¥a nÃ¡stroje zbytoÄne.

VÃ½konnostnÃ© testy: PretoÅ¾e integrujeme viac krokov, sledujeme latenciu. Typicky jedno Pinecone query a jedno API call pridajÃº trochu Äasu, no stÃ¡le by sme sa mali zmestiÅ¥ do niekoÄ¾kÃ½ch sekÃºnd pre odpoveÄ. Otestujeme dotaz, kde sa spravÃ­ naraz viac volanÃ­ (najhorÅ¡Ã­ prÃ­pad) a meriame celkovÃ½ Äas.

Po ÃºspeÅ¡nom otestovanÃ­ je finÃ¡lny stav systÃ©mu takÃ½, Å¾e Geppetto dokÃ¡Å¾e v produkcii plynulo odpovedaÅ¥ aj na komplexnÃ© dotazy vyÅ¾adujÃºce informÃ¡cie z rÃ´znych zdrojov. Z pohÄ¾adu pouÅ¾Ã­vateÄ¾a sa asistent javÃ­ mÃºdrejÅ¡Ã­ a uÅ¾itoÄnejÅ¡Ã­, lebo: - vie rozprÃ¡vaÅ¥ fakty z internej dokumentÃ¡cie (vÄaka RAG/ Pinecone), - mÃ¡ aktuÃ¡lne obchodnÃ© dÃ¡ta z internÃ½ch systÃ©mov (Salesforce), - vie poskytnÃºÅ¥ kontext z poslednÃ½ch komunikÃ¡ciÃ­ (Gong hovory), - a to vÅ¡etko v rÃ¡mci jednÃ©ho rozhovoru, bez nutnosti ruÄne hÄ¾adaÅ¥ informÃ¡cie.

PrÃ­klad finÃ¡lnej interakcie:
UÅ¾Ã­vateÄ¾: "MÃ¡m zajtra stretnutie s Contoso Ltd. ÄŒo by som mal vedieÅ¥?"
Asistent (Geppetto): "(internally: zistÃ­ Å¾e 'Contoso Ltd' je zÃ¡kaznÃ­k -> volÃ¡ search_salesforce, get_gong_transcript...)"
Asistent (odpoveÄ): "Contoso Ltd. je nÃ¡Å¡ dlhoroÄnÃ½ klient. PodÄ¾a CRM aktuÃ¡lne rokujeme o predÄºÅ¾enÃ­ kontraktu (fÃ¡za: NÃ¡vrh zmluvy, poslednÃ½ kontakt pred 3 dÅˆami). Na poslednom hovore zaznelo, Å¾e oÄakÃ¡vajÃº aktualizovanÃº cenovÃº ponuku a upresnenie rozsahu podpory. OdporÃºÄam na stretnutÃ­ zdÃ´razniÅ¥ pridanÃº hodnotu naÅ¡ej sluÅ¾by a pripraviÅ¥ si nÃ¡vrh upravenÃ½ch podmienok podÄ¾a ich poÅ¾iadaviek."

TakÃ¡to odpoveÄ kombinuje znalosti z viacerÃ½ch systÃ©mov v sÃºvislom texte. Geppetto vÄaka toolchain-u pÃ´sobÃ­ kompetentne a kontextovo informovane, ÄÃ­m vÃ½razne zvyÅ¡uje produktivitu uÅ¾Ã­vateÄ¾a.

ğŸ—‚ Relevancia pre Geppetto pipeline
ImplementÃ¡cia Geppetto Toolchain Å¡pecifikovanÃ¡ v tomto dokumente sa zaÄlenÃ­ do existujÃºcej Geppetto pipeline ako novÃ¡ vrstva funkcionality. V rÃ¡mci build/deploy procesu budÃº aktualizovanÃ© nasledovnÃ© Äasti: - KonfigurÃ¡cia GPT asistenta: System prompt bude doplnenÃ½ o definÃ­cie funkciÃ­ a prÃ­klady pouÅ¾itia (podÄ¾a tejto Å¡pecifikÃ¡cie). TaktieÅ¾ parametre volania OpenAI API budÃº obsahovaÅ¥ functions zodpovedajÃºce naÅ¡im akciÃ¡m, aby model mohol robiÅ¥  function_call . - KÃ³dovÃ©
moduly: pinecone_connector.py ,	,  action_dispatcher.py a
prÃ­padne sÃºvisiace sÃºbory budÃº pridanÃ© do codebase. UistÃ­me sa, Å¾e spÄºÅˆajÃº Å¡tandardy kÃ³du (typovÃ© anotÃ¡cie, logging, error handling) a budÃº verzovanÃ© v repozitÃ¡ri. Commit message zavedieme v Å¡tÃ½le: "Add Geppetto Toolchain modules for Pinecone and external actions (Salesforce, Gong integration)". -
IntegrÃ¡cia do servera: HlavnÃ¡ aplikÃ¡cia (napr.	alebo orchestrator service) bude inicializovaÅ¥
QueryContextEngine a ActionDispatcher podÄ¾a nÃ¡vodu vyÅ¡Å¡ie. TaktieÅ¾ sa upravÃ­ logika spracovania
kaÅ¾dÃ©ho dotazu tak, aby kontrolovala	z modelu a volala naÅ¡e moduly. -
Nasadenie middleware: PredpokladÃ¡me, Å¾e middleware (serverless funkcie pre SF a Gong) sÃº nasadenÃ© a funkÄnÃ©. Pipeline by mohla obsahovaÅ¥ krok na overenie dostupnosti tÃ½chto endpointov (napr. health-check ping pri Å¡tarte). - Auto-indexing znalostÃ­: ZnalostnÃ¡ bÃ¡za pre Pinecone by mala byÅ¥
udrÅ¾iavanÃ¡ aktuÃ¡lna. Geppetto pipeline mÃ´Å¾e obsahovaÅ¥ skript	(ako uÅ¾ existuje pre

Builder) rozÅ¡Ã­renÃ½ o extrahovanie relevantnÃ½ch dokumentov a ich pravidelnÃ© indexovanie cez PineconeConnector. TÃ½m zabezpeÄÃ­me, Å¾e RAG mÃ¡ stÃ¡le ÄerstvÃ© dÃ¡ta. - DokumentÃ¡cia a archivÃ¡cia: Tento dokument "Geppetto Toolchain Spec" slÃºÅ¾i ako zdroj pravdy pre tieto zmeny. Bude uloÅ¾enÃ½ v dokumentaÄnom repozitÃ¡ri (Archivon) a prepojenÃ½ tagmi s ostatnÃ½mi Äastiami (Builder Å¡pecifikÃ¡cia, atÄ.). Pri budÃºcich ÃºpravÃ¡ch (napr. pridanie novej akcie) sa tÃ¡to Å¡pecifikÃ¡cia aktualizuje a verzionuje s jasnÃ½m popisom commitov, aby bola zachovanÃ¡ histÃ³ria zmien.

Cez	sa kÄ¾ÃºÄovÃ© informÃ¡cie mÃ´Å¾u exportovaÅ¥ aj do strojovo ÄitateÄ¾nÃ½ch
konfigurÃ¡ciÃ­,   ak   to   architektÃºra   vyÅ¾aduje   â€“   naprÃ­klad   vygenerovanie   sÃºboru
obsahujÃºceho zoznam funkciÃ­ a ich popisy pre potreby nasadenia. TakÃ¡to integrÃ¡cia uÄ¾ahÄuje automatizovanÃ© nasadenie a testovanie: pipeline mÃ´Å¾e naÄÃ­taÅ¥ Å¡pecifikÃ¡ciu, nastaviÅ¥ podÄ¾a nej prostredie a spustiÅ¥ testy.

VÃ½slednÃ¡ Geppetto pipeline tak bude obsahovaÅ¥ nielen Custom GPT Builder vrstvu (Å¡pecifikovanÃº v Geppetto Build Layer dokumente), ale aj Toolchain Orchestration vrstvu (Å¡pecifikovanÃº tu). Obe spolu tvoria komplexnÃ½ systÃ©m: Builder umoÅ¾Åˆuje interaktÃ­vne vytvÃ¡raÅ¥ Å¡peciÃ¡lne GPT konfigurÃ¡cie, a Toolchain ich obohacuje o prÃ­stup k znalostiam a akciÃ¡m. VÅ¡etky komponenty sÃº navrhnutÃ© modulÃ¡rne a v sÃºlade s filozofiou Geppetta, takÅ¾e ÄalÅ¡ie rozÅ¡Ã­renia (napr. integrÃ¡cia inÃ½ch systÃ©mov ako Jira, Calendar, Äi pridanie vizuÃ¡lnych generatÃ­vnych nÃ¡strojov) budÃº moÅ¾nÃ© bez zÃ¡sadnÃ©ho prepisovania architektÃºry.

ğŸ· Tagy



GPT-4.1 Prompting Guide | OpenAI Cookbook
https://cookbook.openai.com/examples/gpt4-1_prompting_guide
Multi-Tool Orchestration with RAG approach using OpenAI's Responses API | OpenAI Cookbook
https://cookbook.openai.com/examples/responses_api/responses_api_tool_orchestration
GPT Actions library - Salesforce & Gong | OpenAI Cookbook
https://cookbook.openai.com/examples/chatgpt/gpt_actions_library/gpt_action_salesforce_gong